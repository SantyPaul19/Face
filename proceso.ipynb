{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d1a6e6-38c8-43fe-9d2c-6c1434147f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando archivos y carpetas...\n",
      "\n",
      "[OK] models\\deploy.prototxt\n",
      "[OK] models\\res10_300x300_ssd_iter_140000.caffemodel\n",
      "[OK] models\\openface_nn4.small2.v1.t7\n",
      "[OK] dataset/: C:\\Users\\Santi\\Documents\\FaceReco\\dataset\n",
      "[FALTA] output/ (creando) â†’ C:\\Users\\Santi\\Documents\\FaceReco\\output\n",
      "Verificando archivos y carpetas...\n",
      "\n",
      "[OK] models\\deploy.prototxt\n",
      "[OK] models\\res10_300x300_ssd_iter_140000.caffemodel\n",
      "[OK] models\\openface_nn4.small2.v1.t7\n",
      "[OK] dataset/: C:\\Users\\Santi\\Documents\\FaceReco\\dataset\n",
      "[OK] output/: C:\\Users\\Santi\\Documents\\FaceReco\\output\n",
      "\n",
      " Todos los modelos estÃ¡n en [OK], continuar.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar rutas y modelos \n",
    "#import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define las rutas de las carpetas\n",
    "MODEL_DIR = Path(\"models\")\n",
    "DATASET_DIR = Path(\"dataset\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "\n",
    "# Define las rutas de los tres archivos de modelo\n",
    "FACE_PROTO = MODEL_DIR / \"deploy.prototxt\"\n",
    "FACE_MODEL = MODEL_DIR / \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "EMBED_MODEL = MODEL_DIR / \"openface_nn4.small2.v1.t7\"\n",
    "\n",
    "def check_paths():\n",
    "    ok = True\n",
    "    print(\"Verificando archivos y carpetas...\\n\")\n",
    "\n",
    "    # Verificar los 3 modelos\n",
    "    for p in [FACE_PROTO, FACE_MODEL, EMBED_MODEL]:\n",
    "        if not p.exists():\n",
    "            print(f\"[FALTA] {p}\")\n",
    "            ok = False\n",
    "        else:\n",
    "            print(f\"[OK] {p}\")\n",
    "\n",
    "    # Verificar dataset y output\n",
    "    if not DATASET_DIR.exists():\n",
    "        print(f\"[FALTA] dataset/ (creando) â†’ {DATASET_DIR.resolve()}\")\n",
    "        DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"[OK] dataset/: {DATASET_DIR.resolve()}\")\n",
    "\n",
    "    if not OUTPUT_DIR.exists():\n",
    "        print(f\"[FALTA] output/ (creando) â†’ {OUTPUT_DIR.resolve()}\")\n",
    "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"[OK] output/: {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "    return ok\n",
    "\n",
    "# Ejecuta la verificaciÃ³n\n",
    "_ = check_paths()\n",
    "\n",
    "if check_paths() == True:\n",
    "    print(\"\\n Todos los modelos estÃ¡n en [OK], continuar.\")\n",
    "else:\n",
    "    print(\"\\n Todos los modelos estÃ¡n en [OK], continuar.\")\n",
    "    print(\" Si alguno dice [FALTA], revisa el nombre o su ubicaciÃ³n en la carpeta 'models/'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a845b156-5915-45ed-bd98-d51d235a4357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Todos los modelos cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos y definir funciones de detecciÃ³n y embeddings ---\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el detector de caras (SSD con ResNet-10)\n",
    "detector = cv2.dnn.readNetFromCaffe(str(FACE_PROTO), str(FACE_MODEL))\n",
    "\n",
    "# Cargar el modelo de embeddings (OpenFace)\n",
    "embedder = cv2.dnn.readNetFromTorch(str(EMBED_MODEL))\n",
    "\n",
    "print(\" Todos los modelos cargados correctamente.\")\n",
    "\n",
    "\n",
    "# FunciÃ³n para detectar la cara mÃ¡s grande en una imagen\n",
    "def detectar_cara_bgr(image_bgr, conf_thresh=0.5, min_side=40):\n",
    "    (h, w) = image_bgr.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image_bgr, (300, 300)),\n",
    "                                 1.0, (300, 300),\n",
    "                                 (104.0, 177.0, 123.0))\n",
    "    detector.setInput(blob)\n",
    "    detections = detector.forward()\n",
    "    best = None\n",
    "    best_area = 0\n",
    "    for i in range(detections.shape[2]):\n",
    "        conf = detections[0, 0, i, 2]\n",
    "        if conf < conf_thresh:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = (detections[0, 0, i, 3:7] * np.array([w, h, w, h])).astype(int)\n",
    "\n",
    "        # Recorte seguro a lÃ­mites\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "        \n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        if area > best_area:\n",
    "            best_area = area\n",
    "            best = (x1, y1, x2, y2, conf)\n",
    "    return best  # None si no hay rostro vÃ¡lido\n",
    "\n",
    "\n",
    "# FunciÃ³n para obtener el embedding (vector 128-D)\n",
    "def embedding_cara(image_bgr, box, margin=0.2):\n",
    "    if box is None:\n",
    "        return None\n",
    "    x1, y1, x2, y2, _ = box\n",
    "    h, w = image_bgr.shape[:2]\n",
    "\n",
    "    # Margen alrededor del rostro\n",
    "    bw, bh = x2 - x1, y2 - y1\n",
    "    dx, dy = int(bw * margin), int(bh * margin)\n",
    "    x1m, y1m = max(0, x1 - dx), max(0, y1 - dy)\n",
    "    x2m, y2m = min(w, x2 + dx), min(h, y2 + dy)\n",
    "\n",
    "    if x2m <= x1m or y2m <= y1m:\n",
    "        return None\n",
    "        \n",
    "    face = image_bgr[y1m:y2m, x1m:x2m]\n",
    "    if face is None or face.size == 0:\n",
    "        return None\n",
    "\n",
    "    face_blob = cv2.dnn.blobFromImage(cv2.resize(face, (96, 96)),\n",
    "                                      1.0/255, (96, 96),\n",
    "                                      (0, 0, 0), swapRB=True, crop=False)\n",
    "    embedder.setInput(face_blob)\n",
    "    vec = embedder.forward()\n",
    "    if vec is None or vec.size == 0:\n",
    "        return None\n",
    "    return vec.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397c929d-7670-45f5-b264-b18850177e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Â¿CuÃ¡ntas imÃ¡genes deseas extraer? (Recomendable = 200):  200\n",
      "ðŸ‘‰ Escribe el nombre de la carpeta donde guardar las imÃ¡genes:  Santiago_Zagal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Guardando imÃ¡genes en: C:\\Users\\Santi\\Documents\\FaceReco\\dataset\\Santiago_Zagal\n",
      "ðŸŽž WhatsApp Video 2025-11-08 at 08.13.52.mp4 â†’ 463 frames | 30.00 fps | 15.43 s\n",
      "âœ… Se guardaron 200 imÃ¡genes en 'C:\\Users\\Santi\\Documents\\FaceReco\\dataset\\Santiago_Zagal'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Â¿Quieres procesar otro video? (s/n):  S\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸšª No seleccionaste video. Fin del proceso.\n"
     ]
    }
   ],
   "source": [
    "# Extraer frames de varios videos, eligiendo carpeta y nÃºmero de imÃ¡genes\n",
    "from tkinter import Tk, filedialog\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Configurar Tkinter para selecciÃ³n de archivos\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    \"\"\"Convierte a nombre de carpeta seguro (sin espacios ni caracteres raros).\"\"\"\n",
    "    text = text.strip().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^A-Za-z0-9_\\-]\", \"\", text) or \"frames_extraidos\"\n",
    "\n",
    "def extraer_frames_de_video(video_path: str, destino_dir: Path, n_frames: int) -> int:\n",
    "    \"\"\"Extrae n_frames equiespaciados del video y los guarda en destino_dir.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ No se pudo abrir el video: {video_path}\")\n",
    "        return 0\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 0\n",
    "    dur = (total_frames / fps) if (fps > 0 and total_frames > 0) else 0\n",
    "    print(f\"ðŸŽž {Path(video_path).name} â†’ {total_frames} frames | {fps:.2f} fps | {dur:.2f} s\")\n",
    "\n",
    "    if total_frames <= 0:\n",
    "        cap.release()\n",
    "        print(\"âš ï¸ El video no reporta frames legibles.\")\n",
    "        return 0\n",
    "\n",
    "    n = min(n_frames, total_frames)\n",
    "    indices = [int(round(i * (total_frames - 1) / (n - 1))) for i in range(n)] if n > 1 else [0]\n",
    "\n",
    "    destino_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    saved = 0\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            print(f\"[AVISO] No se pudo leer el frame {idx}\")\n",
    "            continue\n",
    "        out_file = destino_dir / f\"frame_{idx:06d}.jpg\"\n",
    "        cv2.imwrite(str(out_file), frame)\n",
    "        saved += 1\n",
    "\n",
    "    cap.release()\n",
    "    return saved\n",
    "\n",
    "# Bucle principal\n",
    "while True:\n",
    "    # Seleccionar video\n",
    "    video_path = filedialog.askopenfilename(\n",
    "        title=\"Selecciona un video\",\n",
    "        filetypes=[(\"Videos\", \"*.mp4 *.avi *.mov *.mkv\"), (\"Todos los archivos\", \"*.*\")]\n",
    "    )\n",
    "    if not video_path:\n",
    "        print(\"ðŸšª No seleccionaste video. Fin del proceso.\")\n",
    "        break\n",
    "\n",
    "    # Pedir nÃºmero de imÃ¡genes\n",
    "    try:\n",
    "        n_frames = int(input(\"Â¿CuÃ¡ntas imÃ¡genes deseas extraer? (Recomendable = 200): \").strip() or \"200\")\n",
    "    except ValueError:\n",
    "        n_frames = 200\n",
    "\n",
    "    # Pedir nombre de carpeta\n",
    "    nombre_carpeta = input(\"ðŸ‘‰ Escribe el nombre de la carpeta donde guardar las imÃ¡genes: \").strip()\n",
    "    nombre_carpeta = slugify(nombre_carpeta)\n",
    "    destino_dir = Path.cwd() / \"dataset\" / nombre_carpeta\n",
    "    print(f\"ðŸ“ Guardando imÃ¡genes en: {destino_dir.resolve()}\")\n",
    "\n",
    "    # Extraer frames\n",
    "    guardadas = extraer_frames_de_video(video_path, destino_dir, n_frames)\n",
    "    print(f\"âœ… Se guardaron {guardadas} imÃ¡genes en '{destino_dir}'\")\n",
    "\n",
    "    # Preguntar si continuarV\n",
    "    seguir = input(\"Â¿Quieres procesar otro video? (s/n): \").strip().lower()\n",
    "    if seguir not in (\"s\", \"si\", \"sÃ­\"):\n",
    "        print(\"âœ”ï¸ Proceso finalizado.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4504ae6f-7a01-447c-a824-b7103e107047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Procesando 737 imÃ¡genes...\n",
      "\n",
      "   â†’ Procesadas 100/737 imÃ¡genes...\n",
      "   â†’ Procesadas 200/737 imÃ¡genes...\n",
      "   â†’ Procesadas 300/737 imÃ¡genes...\n",
      "   â†’ Procesadas 400/737 imÃ¡genes...\n",
      "   â†’ Procesadas 500/737 imÃ¡genes...\n",
      "   â†’ Procesadas 600/737 imÃ¡genes...\n",
      "   â†’ Procesadas 700/737 imÃ¡genes...\n",
      "   â†’ Procesadas 737/737 imÃ¡genes...\n",
      "\n",
      " RESULTADOS \n",
      "âœ… Embeddings generados: 737\n",
      "ðŸ‘¥ Personas detectadas: ['Santiago_Zagal', 'Vinicio_Quilumba']\n",
      "ðŸ“Š Resumen de fallos: {}\n",
      " ðŸ’¾ Embeddings guardados en: C:\\Users\\Santi\\Documents\\FaceReco\\output\\embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "# Generar embeddings de todas las imÃ¡genes en dataset/ (reemplazando archivo si ya existe) \n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import pickle\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from imutils import paths\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# CONFIGURACIÃ“N\n",
    "#DATASET_DIR = Path(\"dataset\")\n",
    "BASE_DIR = Path.cwd()\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "EMB_PATH    = OUTPUT_DIR / \"embeddings.pickle\"\n",
    "#LOG_DIR     = DATASET_DIR / \"diagnostico\"\n",
    "LOG_DIR     = BASE_DIR / \"diagnostico\"\n",
    "NOFACE_DIR  = LOG_DIR / \"sin_rostro\"\n",
    "EMBFAIL_DIR = LOG_DIR / \"embedding_fallido\"\n",
    "CSV_FALLOS  = LOG_DIR / \"fallos.csv\"\n",
    "\n",
    "# Rotaciones y umbrales\n",
    "CONF_LIST  = [0.50, 0.35, 0.25]\n",
    "ROTATIONS  = [0, 90, 180, 270]  # grados\n",
    "MIN_SIDE   = 40                 # tamaÃ±o mÃ­nimo de cara (px)\n",
    "MARGIN     = 0.20               # margen alrededor del bbox para el embedding\n",
    "\n",
    "# Asegurar carpetas\n",
    "if not DATASET_DIR.exists():\n",
    "    raise FileNotFoundError(f\"No existe la carpeta del dataset: {DATASET_DIR}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOFACE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EMBFAIL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rotar_bgr(img_bgr, angle):\n",
    "    if angle == 0:\n",
    "        return img_bgr\n",
    "    elif angle == 90:\n",
    "        return cv2.rotate(img_bgr, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif angle == 180:\n",
    "        return cv2.rotate(img_bgr, cv2.ROTATE_180)\n",
    "    else:  # 270\n",
    "        return cv2.rotate(img_bgr, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "def safe_print(*args, **kwargs):\n",
    "    \"\"\"Print con flush forzado para evitar cortes/renglones truncados.\"\"\"\n",
    "    print(*args, **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Listar imÃ¡genes (excluir checkpoints/ocultas)\n",
    "image_paths = [\n",
    "    p for p in paths.list_images(str(DATASET_DIR))\n",
    "    if \".ipynb_checkpoints\" not in p and not Path(p).parent.name.startswith(\".\")\n",
    "]\n",
    "if not image_paths:\n",
    "    raise RuntimeError(f\"âš ï¸ No se encontraron imÃ¡genes dentro de {DATASET_DIR}\")\n",
    "\n",
    "safe_print(f\"ðŸ” Procesando {len(image_paths)} imÃ¡genes...\\n\")\n",
    "\n",
    "embeddings, labels = [], []\n",
    "fail_reasons = Counter()\n",
    "fallos_rows = []  # para CSV\n",
    "\n",
    "# Procesar\n",
    "for (i, img_path) in enumerate(image_paths, start=1):\n",
    "    img_path = Path(img_path)\n",
    "    person = img_path.parent.name\n",
    "    img0 = cv2.imread(str(img_path))\n",
    "\n",
    "    if img0 is None:\n",
    "        safe_print(f\"[âŒ] No se pudo leer {img_path}\")\n",
    "        fail_reasons[\"imread\"] += 1\n",
    "        fallos_rows.append([str(img_path), \"imread\", \"No se pudo leer\"])\n",
    "        # Mover a diagnostico\n",
    "        try:\n",
    "            shutil.copy2(str(img_path), LOG_DIR / img_path.name)\n",
    "        except Exception:\n",
    "            pass\n",
    "        continue\n",
    "\n",
    "    success = False\n",
    "    bbox_usada = None\n",
    "\n",
    "    for angle in ROTATIONS:\n",
    "        img = rotar_bgr(img0, angle)\n",
    "\n",
    "        # Intentar detecciÃ³n con distintos umbrales\n",
    "        box = None\n",
    "        for thr in CONF_LIST:\n",
    "            try:\n",
    "                box = detectar_cara_bgr(img, conf_thresh=thr, min_side=MIN_SIDE)\n",
    "            except Exception as e:\n",
    "                box = None\n",
    "            if box is not None:\n",
    "                break\n",
    "\n",
    "        if box is None:\n",
    "            continue  # probar otra rotaciÃ³n\n",
    "\n",
    "        # Intentar embedding con margen\n",
    "        try:\n",
    "            vec = embedding_cara(img, box, margin=MARGIN)\n",
    "        except Exception as e:\n",
    "            vec = None\n",
    "\n",
    "        if vec is not None:\n",
    "            embeddings.append(vec)\n",
    "            labels.append(person)\n",
    "            success = True\n",
    "            bbox_usada = box\n",
    "            break  # Â¡listo para esta imagen!\n",
    "\n",
    "    if not success:\n",
    "        # DiagnÃ³stico: Â¿fallÃ³ detecciÃ³n o embedding?\n",
    "        box_dbg = None\n",
    "        for thr in CONF_LIST:\n",
    "            try:\n",
    "                box_dbg = detectar_cara_bgr(img0, conf_thresh=thr, min_side=MIN_SIDE)\n",
    "            except Exception:\n",
    "                box_dbg = None\n",
    "            if box_dbg is not None:\n",
    "                break\n",
    "\n",
    "        if box_dbg is None:\n",
    "            safe_print(f\"[âš ï¸] No se detectÃ³ rostro en {img_path}\")\n",
    "            fail_reasons[\"sin_rostro\"] += 1\n",
    "            fallos_rows.append([str(img_path), \"sin_rostro\", \"DetecciÃ³n fallida (todas las rotaciones)\"])\n",
    "            # Copiar al folder de no-face (para inspecciÃ³n)\n",
    "            try:\n",
    "                shutil.copy2(str(img_path), NOFACE_DIR / img_path.name)\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            safe_print(f\"[âš ï¸] No se pudo generar embedding para {img_path}\")\n",
    "            fail_reasons[\"embedding_fallido\"] += 1\n",
    "            fallos_rows.append([str(img_path), \"embedding_fallido\", \"Encoder devolviÃ³ None\"])\n",
    "            # Copiar al folder de embedding-fallo\n",
    "            try:\n",
    "                shutil.copy2(str(img_path), EMBFAIL_DIR / img_path.name)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Progreso cada 100 imÃ¡genes\n",
    "    if (i % 100 == 0) or (i == len(image_paths)):\n",
    "        safe_print(f\"   â†’ Procesadas {i}/{len(image_paths)} imÃ¡genes...\")\n",
    "\n",
    "# ===== Resultados =====\n",
    "safe_print(\"\\n RESULTADOS \")\n",
    "safe_print(f\"âœ… Embeddings generados: {len(embeddings)}\")\n",
    "safe_print(f\"ðŸ‘¥ Personas detectadas: {sorted(set(labels))}\")\n",
    "safe_print(f\"ðŸ“Š Resumen de fallos: {dict(fail_reasons)}\")\n",
    "\n",
    "# Guardar CSV de fallos\n",
    "if fallos_rows:\n",
    "    with open(CSV_FALLOS, \"w\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "        writer = csv.writer(fcsv)\n",
    "        writer.writerow([\"ruta_imagen\", \"tipo_fallo\", \"detalle\"])\n",
    "        writer.writerows(fallos_rows)\n",
    "    safe_print(f\"ðŸ§¾ CSV de fallos: {CSV_FALLOS}\")\n",
    "\n",
    "# Guardar embeddings (reemplaza si existe)\n",
    "if EMB_PATH.exists():\n",
    "    try:\n",
    "        os.remove(EMB_PATH)\n",
    "        safe_print(f\"âš™ï¸ Archivo existente eliminado: {EMB_PATH.name}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"No se pudo eliminar {EMB_PATH}: {e}\")\n",
    "\n",
    "payload = {\"embeddings\": embeddings, \"names\": labels, \"fecha\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "with open(EMB_PATH, \"wb\") as f:\n",
    "    pickle.dump(payload, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "safe_print(f\" ðŸ’¾ Embeddings guardados en: {EMB_PATH.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a287372c-5205-43e8-83ac-0bc54ecf9ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (737, 128)\n",
      "Clases: ['Santiago_Zagal', 'Vinicio_Quilumba']\n",
      "âž¡ï¸ Mejor configuraciÃ³n: {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "\n",
      "=== Reporte de clasificaciÃ³n ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Santiago_Zagal       1.00      1.00      1.00        88\n",
      "Vinicio_Quilumba       1.00      1.00      1.00        60\n",
      "\n",
      "        accuracy                           1.00       148\n",
      "       macro avg       1.00      1.00      1.00       148\n",
      "    weighted avg       1.00      1.00      1.00       148\n",
      "\n",
      "Matriz de confusiÃ³n:\n",
      " [[88  0]\n",
      " [ 0 60]]\n",
      "ðŸ”§ Umbral de confianza recomendado: 0.500\n",
      "\n",
      "ðŸ’¾ Guardado: \n",
      " - output\\recognizer_svm.pickle\n",
      " - output\\label_encoder.pickle\n",
      " - output\\threshold.pkl\n",
      " - output\\open_set_meta.pkl\n"
     ]
    }
   ],
   "source": [
    "# Entrenar SVM y guardar artefactos (eliminar y reemplazar si existen)\n",
    "import os, pickle, numpy as np, warnings\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Ignorar advertencias de mÃ©tricas indefinidas ðŸš«\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Rutas\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EMB_PATH = OUTPUT_DIR / \"embeddings.pickle\"\n",
    "RECOGNIZER_PATH = OUTPUT_DIR / \"recognizer_svm.pickle\"\n",
    "ENCODER_PATH = OUTPUT_DIR / \"label_encoder.pickle\"\n",
    "THRESH_PATH = OUTPUT_DIR / \"threshold.pkl\"\n",
    "OPEN_META = OUTPUT_DIR / \"open_set_meta.pkl\"\n",
    "\n",
    "# 1) Cargar embeddings\n",
    "with open(EMB_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X = np.array(data[\"embeddings\"])   # (n_muestras, 128)\n",
    "names = np.array(data[\"names\"])    # etiquetas de texto\n",
    "\n",
    "print(\"Shape de X:\", X.shape)\n",
    "print(\"Clases:\", sorted(set(names)))\n",
    "\n",
    "# 2) Codificar etiquetas\n",
    "le = LabelEncoder().fit(names)\n",
    "y = le.transform(names)\n",
    "\n",
    "# 3) Train/Test split si hay datos suficientes (>=2 clases y >=5 muestras)\n",
    "n_clases = len(np.unique(y))\n",
    "min_por_clase = min(Counter(y).values())\n",
    "hacer_split = (n_clases >= 2) and (len(y) >= 5)\n",
    "\n",
    "if hacer_split and min_por_clase >= 2:\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=0.20, stratify=y, random_state=42\n",
    "    )\n",
    "else:\n",
    "    Xtr, Xte, ytr, yte = X, X, y, y\n",
    "    print(\"\\n(Conjunto pequeÃ±o o con clases de 1 muestra: se entrenarÃ¡ sin split de validaciÃ³n)\")\n",
    "\n",
    "# 4) Pipeline: NormalizaciÃ³n L2 + SVM y bÃºsqueda de hiperparÃ¡metros\n",
    "pipe = make_pipeline(\n",
    "    Normalizer(norm=\"l2\"),\n",
    "    SVC(probability=True, class_weight=\"balanced\", random_state=42)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svc__C\": [0.1, 1, 10, 100],\n",
    "    \"svc__gamma\": [\"scale\", 0.01, 0.001]  # gamma se usa solo con RBF\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=min(5, max(2, min(Counter(ytr).values()))),\n",
    "                     shuffle=True, random_state=42)\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid, cv=cv, n_jobs=-1, verbose=0)\n",
    "gs.fit(Xtr, ytr)\n",
    "clf = gs.best_estimator_\n",
    "print(\"âž¡ï¸ Mejor configuraciÃ³n:\", gs.best_params_)\n",
    "\n",
    "\n",
    "# Normalizamos X con el mismo normalizer del pipeline\n",
    "X_norm = clf.named_steps[\"normalizer\"].transform(X)\n",
    "\n",
    "class_means = {}\n",
    "class_thr = {}\n",
    "\n",
    "for idx_cls, cls_name in enumerate(le.classes_):\n",
    "    idx = np.where(y == idx_cls)[0]\n",
    "    Xc = X_norm[idx]\n",
    "    mu = Xc.mean(axis=0)                 # centroide de la clase\n",
    "    dists = cosine_distances(Xc, [mu]).ravel()\n",
    "    \n",
    "    # Umbral por clase: p.ej. percentil 95 de las distancias intra-clase\n",
    "    t = np.quantile(dists, 0.95)\n",
    "\n",
    "    class_means[cls_name] = mu\n",
    "    class_thr[cls_name] = float(t)\n",
    "\n",
    "open_set_meta = {\n",
    "    \"class_means\": class_means,\n",
    "    \"class_thr\": class_thr,\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / \"open_set_meta.pkl\", \"wb\") as f:\n",
    "    pickle.dump(open_set_meta, f)\n",
    "\n",
    "\n",
    "# 5) EvaluaciÃ³n y cÃ¡lculo de umbral de confianza (para open-set)\n",
    "def find_best_threshold(model, Xv, yv):\n",
    "    \"\"\"Devuelve el mejor umbral de probabilidad para etiquetar 'Desconocido'.\"\"\"\n",
    "    if len(Xv) == 0:\n",
    "        return 0.7  # valor razonable por defecto\n",
    "    probs = model.predict_proba(Xv)\n",
    "    pmax = probs.max(axis=1)\n",
    "    pred_idx = probs.argmax(axis=1)\n",
    "    # probar umbrales y maximizar F1 macro en los casos aceptados\n",
    "    best_t, best_f1 = 0.6, -1\n",
    "    for t in np.linspace(0.5, 0.95, 10):\n",
    "        aceptadas = pmax >= t\n",
    "        if not np.any(aceptadas):\n",
    "            continue\n",
    "        f1 = f1_score(yv[aceptadas], pred_idx[aceptadas], average=\"macro\", zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return float(best_t)\n",
    "\n",
    "if hacer_split and (Xte is not Xtr):\n",
    "    # Informe clÃ¡sico\n",
    "    ypred = clf.predict(Xte)\n",
    "    print(\"\\n=== Reporte de clasificaciÃ³n ===\")\n",
    "    print(classification_report(yte, ypred, target_names=le.classes_))\n",
    "    print(\"Matriz de confusiÃ³n:\\n\", confusion_matrix(yte, ypred))\n",
    "\n",
    "    # Umbral aprendido en validaciÃ³n\n",
    "    best_t = find_best_threshold(clf, Xte, yte)\n",
    "else:\n",
    "    best_t = 0.7  # por defecto si no hay validaciÃ³n\n",
    "\n",
    "print(f\"ðŸ”§ Umbral de confianza recomendado: {best_t:.3f}\")\n",
    "\n",
    "# 6) Eliminar existentes y guardar artefactos nuevos\n",
    "for path in (RECOGNIZER_PATH, ENCODER_PATH, THRESH_PATH):\n",
    "    if path.exists():\n",
    "        os.remove(path)\n",
    "        print(f\"âš™ï¸ Eliminado archivo existente: {path.name}\")\n",
    "\n",
    "with open(RECOGNIZER_PATH, \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "with open(ENCODER_PATH, \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "with open(THRESH_PATH, \"wb\") as f:\n",
    "    pickle.dump(best_t, f)\n",
    "with open(OPEN_META, \"wb\") as f:\n",
    "    pickle.dump(best_t, f)\n",
    "\n",
    "print(\"\\nðŸ’¾ Guardado: \")\n",
    "print(f\" - {RECOGNIZER_PATH}\")\n",
    "print(f\" - {ENCODER_PATH}\")\n",
    "print(f\" - {THRESH_PATH}\")\n",
    "print(f\" - {OPEN_META}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f362921f-da51-41a6-8dd7-707d9192f579",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inferencia en imagen con VARIOS rostros\n",
    "import cv2, numpy as np, pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Cargar clasificador, encoder y umbral UNA SOLA VEZ ---\n",
    "clf = pickle.load(open(\"output/recognizer_svm.pickle\",\"rb\"))\n",
    "le  = pickle.load(open(\"output/label_encoder.pickle\",\"rb\"))\n",
    "\n",
    "THRESH_PATH = Path(\"output/threshold.pkl\")\n",
    "if THRESH_PATH.exists():\n",
    "    BEST_T = float(pickle.load(open(THRESH_PATH, \"rb\")))\n",
    "else:\n",
    "    BEST_T = 0.7  # por defecto si no hay threshold entrenado\n",
    "    print(f\"â„¹ï¸ No se encontrÃ³ {THRESH_PATH.name}. Usando umbral por defecto: {BEST_T}\")\n",
    "\n",
    "def _get_boxes(img, conf_det=0.5):\n",
    "    \"\"\"\n",
    "    Devuelve una lista de cajas [ (x1,y1,x2,y2,score), ... ].\n",
    "    Intenta usar detectar_caras_bgr(); si no existe, usa detectar_cara_bgr().\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    try:\n",
    "        # Si tienes una funciÃ³n multi-cara, Ãºsala\n",
    "        boxes = detectar_caras_bgr(img, conf_thresh=conf_det)  # debe devolver lista\n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "    except NameError:\n",
    "        # Fallback: versiÃ³n una sola cara\n",
    "        b = detectar_cara_bgr(img, conf_thresh=conf_det)\n",
    "        if b is not None:\n",
    "            boxes = [b]\n",
    "    return boxes\n",
    "\n",
    "def predecir_varios_en_imagen(path, conf_det=0.5, conf_cls=None, out_path=None):\n",
    "    \"\"\"\n",
    "    Detecta mÃºltiples rostros, clasifica cada uno y dibuja etiqueta/probabilidad.\n",
    "    - conf_det: umbral del detector de rostros.\n",
    "    - conf_cls: umbral de aceptaciÃ³n (si None, usa BEST_T).\n",
    "    - out_path: si se pasa, guarda la imagen anotada.\n",
    "    Devuelve (img_anotada, resultados) donde resultados es lista de dicts.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"No se pudo leer la imagen: {path}\")\n",
    "\n",
    "    boxes = _get_boxes(img, conf_det=conf_det)\n",
    "    if not boxes:\n",
    "        print(\"âš ï¸ No se detectaron rostros.\")\n",
    "        return img, []\n",
    "\n",
    "    thr = float(conf_cls) if conf_cls is not None else BEST_T\n",
    "    resultados = []\n",
    "\n",
    "    for k, box in enumerate(boxes):\n",
    "        (x1, y1, x2, y2, *rest) = box\n",
    "        vec = embedding_cara(img, box)\n",
    "        if vec is None:\n",
    "            print(f\"âš ï¸ No se pudo obtener embedding para rostro #{k+1}.\")\n",
    "            continue\n",
    "\n",
    "        probs = clf.predict_proba([vec])[0]\n",
    "        j = int(np.argmax(probs))\n",
    "        prob = float(probs[j])\n",
    "        name = le.classes_[j] if prob >= thr else \"Desconocido\"\n",
    "\n",
    "        # Dibujo\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        y_text = max(20, y1 - 10)\n",
    "        cv2.putText(\n",
    "            img, f\"{name}: {prob:.2f}\",\n",
    "            (x1, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2\n",
    "        )\n",
    "\n",
    "        resultados.append({\n",
    "            \"box\": (x1, y1, x2, y2),\n",
    "            \"score_det\": rest[0] if rest else None,\n",
    "            \"pred_clase_idx\": j,\n",
    "            \"pred_nombre\": name,\n",
    "            \"pred_confianza\": prob\n",
    "        })\n",
    "\n",
    "    if out_path:\n",
    "        cv2.imwrite(out_path, img)\n",
    "        print(f\"ðŸ’¾ Guardado: {out_path}\")\n",
    "\n",
    "    return img, resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfec52f3-0f37-45ba-bbde-81247f6a56cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predecir_en_imagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Coloca una imagen 'prueba.jpg' en tu carpeta del proyecto\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mpredecir_en_imagen\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagen2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicciones/prediccion.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predecir_en_imagen' is not defined"
     ]
    }
   ],
   "source": [
    "# Coloca una imagen 'prueba.jpg' en tu carpeta del proyecto\n",
    "_ = predecir_en_imagen(\"imagen2.png\", out_path=\"predicciones/prediccion.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d508de5-6823-4821-a79f-2fe12c7c1fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Guardado: imagen21.png\n",
      "[{'box': (321, 337, 418, 460), 'score_det': 0.9932352, 'pred_clase_idx': 5, 'pred_nombre': 'Vinicio_Quilumba', 'pred_confianza': 0.8507961302466296}]\n"
     ]
    }
   ],
   "source": [
    "img_annot, res = predecir_varios_en_imagen(\n",
    "    \"imagen2.png\",\n",
    "    conf_det=0.5,       # detector mÃ¡s/menos estricto\n",
    "    conf_cls=None,      # usa el umbral aprendido (threshold.pkl)\n",
    "    out_path=\"predicciones/imagen21.png\"\n",
    ")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382d5da7-9b48-4f71-8a7e-6ec611339939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Guardado: imagen12.png\n",
      "[{'box': (199, 309, 271, 406), 'score_det': 0.6512687, 'pred_clase_idx': 2, 'pred_nombre': 'Santiago_Zagal', 'pred_confianza': 0.8554697998297164}]\n"
     ]
    }
   ],
   "source": [
    "img_annot, res = predecir_varios_en_imagen(\n",
    "    \"imagen1.jpeg\",\n",
    "    conf_det=0.5,       # detector mÃ¡s/menos estricto\n",
    "    conf_cls=None,      # usa el umbral aprendido (threshold.pkl)\n",
    "    out_path=\"predicciones/imagen12.png\"\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80341b46-3531-452a-bf86-0da12701a1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reconocimiento)",
   "language": "python",
   "name": "facepro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
