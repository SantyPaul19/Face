{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bffdaac-8d45-4ad9-ad07-391d210c75d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Umbral cargado desde threshold.pkl: 0.500\n",
      "‚úÖ Embeddings de base cargados: (737, 128)\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np, pickle, time\n",
    "from pathlib import Path\n",
    "\n",
    "# 1Ô∏èCargar clasificador (SVM), codificador y umbral\n",
    "clf = pickle.load(open(\"output/recognizer_svm.pickle\",\"rb\"))\n",
    "le  = pickle.load(open(\"output/label_encoder.pickle\",\"rb\"))\n",
    "\n",
    "THRESH_PATH = Path(\"output/threshold.pkl\")\n",
    "if THRESH_PATH.exists():\n",
    "    BEST_T = float(pickle.load(open(THRESH_PATH, \"rb\")))\n",
    "    print(f\"‚úÖ Umbral cargado desde {THRESH_PATH.name}: {BEST_T:.3f}\")\n",
    "else:\n",
    "    BEST_T = 0.7  # valor por defecto\n",
    "    print(f\"‚ÑπÔ∏è No se encontr√≥ {THRESH_PATH.name}. Usando umbral por defecto: {BEST_T}\")\n",
    "\n",
    "# Cargar embeddings de entrenamiento para control de \"desconocido\"\n",
    "EMB_DB_PATH = Path(\"output/embeddings.pickle\")\n",
    "X_db_norm = None\n",
    "names_db = None\n",
    "normalizer = None\n",
    "\n",
    "if EMB_DB_PATH.exists():\n",
    "    data_db = pickle.load(open(EMB_DB_PATH, \"rb\"))\n",
    "    X_db = np.array(data_db[\"embeddings\"])\n",
    "    names_db = np.array(data_db[\"names\"])\n",
    "\n",
    "    # Normalizador del pipeline SVM (el mismo que usaste al entrenar)\n",
    "    if hasattr(clf, \"named_steps\") and \"normalizer\" in clf.named_steps:\n",
    "        normalizer = clf.named_steps[\"normalizer\"]\n",
    "        X_db_norm = normalizer.transform(X_db)\n",
    "        print(f\"‚úÖ Embeddings de base cargados: {X_db_norm.shape}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è El clasificador no tiene 'normalizer' en named_steps; no se usar√° control por distancia.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No se encontr√≥ embeddings.pickle; no se usar√° control por distancia.\")\n",
    "\n",
    "# Cargar modelo de detecci√≥n facial (SSD OpenCV)\n",
    "FACE_PROTO = Path(\"models/deploy.prototxt\")\n",
    "FACE_MODEL = Path(\"models/res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "detector = cv2.dnn.readNetFromCaffe(str(FACE_PROTO), str(FACE_MODEL))\n",
    "\n",
    "def detectar_caras_bgr(img, conf_thresh=0.5):\n",
    "    \"\"\"Detecta rostros en una imagen BGR y devuelve [(x1,y1,x2,y2,score), ...]\"\"\"\n",
    "    (h, w) = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300),\n",
    "                                 (104.0, 177.0, 123.0))\n",
    "    detector.setInput(blob)\n",
    "    detections = detector.forward()\n",
    "    boxes = []\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence < conf_thresh:\n",
    "            continue\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w-1, x2), min(h-1, y2)\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            boxes.append((x1, y1, x2, y2, float(confidence)))\n",
    "    return boxes\n",
    "\n",
    "# Cargar modelo de embeddings (OpenFace)\n",
    "EMBED_MODEL = Path(\"models/openface_nn4.small2.v1.t7\")\n",
    "embedder = cv2.dnn.readNetFromTorch(str(EMBED_MODEL))\n",
    "\n",
    "def embedding_cara(img, box):\n",
    "    \"\"\"Obtiene el embedding (vector 128D) del rostro recortado\"\"\"\n",
    "    (x1, y1, x2, y2, *_) = box\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    if face.size == 0:\n",
    "        return None\n",
    "    face_blob = cv2.dnn.blobFromImage(cv2.resize(face, (96, 96)),\n",
    "                                      1.0/255, (96, 96),\n",
    "                                      (0, 0, 0), swapRB=True, crop=False)\n",
    "    embedder.setInput(face_blob)\n",
    "    vec = embedder.forward()\n",
    "    return vec.flatten()\n",
    "\n",
    "def _draw_label(img, text, x, y, color):\n",
    "    \"\"\"Texto con fondo para mejor visibilidad\"\"\"\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "    cv2.rectangle(img, (x, y - th - 8), (x + tw, y), (0,0,0), -1)\n",
    "    cv2.putText(img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "# Reproductor + reconocimiento (video o webcam)\n",
    "def demo_reproductor(\n",
    "    source,\n",
    "    conf_det=0.5,\n",
    "    conf_cls=None,       # si None, usa BEST_T cargado\n",
    "    resize_ratio=0.5,    # Factor de rendimiento\n",
    "    frame_stride=1,      # (de momento sin usar, se podr√≠a usar para saltar frames)\n",
    "    show_fps=True,\n",
    "    save_out=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Controles:\n",
    "      [ESPACIO] Pausa/Reanuda  |  [S] Snapshot  |  [Q]/[ESC] Salir\n",
    "      [‚Üí] Avanza ~1s (solo videos)  |  [‚Üê] Retrocede ~1s (solo videos)\n",
    "    \"\"\"\n",
    "    thr = float(conf_cls) if conf_cls is not None else BEST_T\n",
    "    print(f\"üéØ Umbral de reconocimiento (SVM prob): {thr:.2f}\")\n",
    "\n",
    "    # Umbrales adicionales\n",
    "    thr_gap = 0.15  # gap m√≠nimo entre p1 y p2\n",
    "    thr_sim = 0.60  # similitud coseno m√≠nima con la base para aceptarlo como conocido\n",
    "\n",
    "    is_cam = isinstance(source, int)\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"No se pudo abrir la fuente: {source}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    delay_ms = int(1000.0 / fps)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if not is_cam else -1\n",
    "\n",
    "    writer = None\n",
    "    if save_out:\n",
    "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        if resize_ratio:\n",
    "            width = int(width * resize_ratio)\n",
    "            height = int(height * resize_ratio)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*(\"mp4v\" if str(save_out).endswith(\".mp4\") else \"XVID\"))\n",
    "        writer = cv2.VideoWriter(str(save_out), fourcc, fps, (width, height))\n",
    "        #print(f\"üíæ Guardando video anotado en: {save_out}\")\n",
    "\n",
    "    snap_dir = Path(\"snapshots\")\n",
    "    snap_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    paused = False\n",
    "    prev_time = time.time()\n",
    "    fps_vis = 0.0\n",
    "\n",
    "    print(\"‚ñ∂ Reproducci√≥n iniciada. [ESPACIO]=pausa, [S]=snapshot, [Q]/[ESC]=salir\")\n",
    "\n",
    "    while True:\n",
    "        if not paused:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                print(\"‚èπ Fin del video o error al leer frame.\")\n",
    "                break\n",
    "\n",
    "            if resize_ratio and 0 < resize_ratio < 1.0:\n",
    "                frame = cv2.resize(frame, None, fx=resize_ratio, fy=resize_ratio)\n",
    "\n",
    "            boxes = detectar_caras_bgr(frame, conf_thresh=conf_det)\n",
    "\n",
    "            for box in boxes:\n",
    "                (x1, y1, x2, y2, *rest) = box\n",
    "                vec = embedding_cara(frame, (x1, y1, x2, y2, *rest))\n",
    "                if vec is None:\n",
    "                    continue\n",
    "\n",
    "                # Predicci√≥n SVM\n",
    "                probs = clf.predict_proba([vec])[0]\n",
    "\n",
    "                order = np.argsort(probs)[::-1]\n",
    "                j1 = int(order[0])\n",
    "                p1 = float(probs[j1])\n",
    "\n",
    "                if len(order) > 1:\n",
    "                    j2 = int(order[1])\n",
    "                    p2 = float(probs[j2])\n",
    "                else:\n",
    "                    j2, p2 = j1, 0.0\n",
    "\n",
    "                pred_name = le.classes_[j1]\n",
    "\n",
    "                # Similitud con embeddings de base (si est√°n disponibles)\n",
    "                sim_max = None\n",
    "                name_nn = None\n",
    "                if (X_db_norm is not None) and (normalizer is not None):\n",
    "                    # normalizamos el embedding actual igual que los de entrenamiento\n",
    "                    vec_norm = normalizer.transform([vec])[0]   # (128,)\n",
    "\n",
    "                    # producto punto porque ya est√°n L2-normalizados ‚Üí coseno\n",
    "                    sims = X_db_norm @ vec_norm                 # (N,)\n",
    "                    idx_max = int(np.argmax(sims))\n",
    "                    sim_max = float(sims[idx_max])\n",
    "                    name_nn = names_db[idx_max]\n",
    "\n",
    "                # Reglas para \"Desconocido\"\n",
    "                is_unknown = False\n",
    "\n",
    "                # Regla de probabilidad y gap\n",
    "                if (p1 < thr) or ((p1 - p2) < thr_gap):\n",
    "                    is_unknown = True\n",
    "\n",
    "                # Regla de similitud en el espacio de embeddings\n",
    "                if sim_max is not None and sim_max < thr_sim:\n",
    "                    is_unknown = True\n",
    "\n",
    "                # (Opcional) si SVM y vecino m√°s cercano discrepan, tambi√©n lo marcamos sospechoso\n",
    "                if (name_nn is not None) and (pred_name != name_nn):\n",
    "                    is_unknown = True\n",
    "\n",
    "                # Dibujar resultado\n",
    "                if is_unknown:\n",
    "                    name = \"Desconocido\"\n",
    "                    color = (0, 0, 255)\n",
    "                else:\n",
    "                    name = pred_name\n",
    "                    color = (0, 255, 0)\n",
    "\n",
    "                texto = f\"{name}: {p1:.2f}\"\n",
    "                if sim_max is not None:\n",
    "                    texto += f\" | sim:{sim_max:.2f}\"\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                _draw_label(frame, texto, x1, y1, color)\n",
    "\n",
    "            if show_fps:\n",
    "                now = time.time()\n",
    "                dt = now - prev_time\n",
    "                if dt > 0:\n",
    "                    fps_vis = 0.9*fps_vis + 0.1*(1.0/dt) if fps_vis > 0 else 1.0/dt\n",
    "                prev_time = now\n",
    "                _draw_label(frame, f\"FPS: {fps_vis:.1f}\", 10, 25, (0,255,255))\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.write(frame)\n",
    "\n",
    "            cv2.imshow(\"Reconocimiento facial (Video)\", frame)\n",
    "\n",
    "        key = cv2.waitKey(0 if paused else delay_ms) & 0xFF\n",
    "        if key in (ord('q'), 27):  # q o ESC\n",
    "            break\n",
    "        elif key == ord(' '):      # espacio: pausa/reanuda\n",
    "            paused = not paused\n",
    "        elif key == ord('s'):      # snapshot\n",
    "            snap_path = snap_dir / f\"snapshot_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(str(snap_path), frame)\n",
    "            print(f\"üíæ Snapshot guardado: {snap_path}\")\n",
    "\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚èπ Reproducci√≥n finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9cfc960-bd50-4ed4-9154-ecba8816596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Video seleccionado: Video.mp4\n",
      "üéØ Umbral de reconocimiento (SVM prob): 0.50\n",
      "‚ñ∂ Reproducci√≥n iniciada. [ESPACIO]=pausa, [S]=snapshot, [Q]/[ESC]=salir\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045859.jpg\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045860.jpg\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045861.jpg\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045863.jpg\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045864.jpg\n",
      "üíæ Snapshot guardado: snapshots\\snapshot_1764045865.jpg\n",
      "‚èπ Reproducci√≥n finalizada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main: seleccionar video con Tkinter\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # üß≠ Abrir di√°logo para seleccionar el video\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Ocultar ventana ra√≠z\n",
    "    video_path = filedialog.askopenfilename(\n",
    "        title=\"Selecciona el video a procesar\",\n",
    "        initialdir=\"video\",\n",
    "        filetypes=[(\"Archivos de video\", \"*.mp4 *.avi *.mov *.mkv\")]\n",
    "    )\n",
    "    if not video_path:\n",
    "        print(\"‚ùå No se seleccion√≥ ning√∫n video. Cancelado.\")\n",
    "        exit()\n",
    "\n",
    "    src_video = Path(video_path)\n",
    "    print(f\"üé¨ Video seleccionado: {src_video.name}\")\n",
    "\n",
    "    # üìÅ Nombre de salida (mismo nombre + _anotado)\n",
    "    save_out =  f\"/video/{src_video.stem}_anotado{src_video.suffix}\"\n",
    "\n",
    "    # üß† Ejecutar reconocimiento\n",
    "    demo_reproductor(\n",
    "        str(src_video),\n",
    "        conf_det=0.5,\n",
    "        conf_cls=None,     # o por ejemplo 0.9 si quieres ser m√°s estricto\n",
    "        resize_ratio=0.8,\n",
    "        frame_stride=1,\n",
    "        show_fps=True,\n",
    "        save_out=str(save_out)\n",
    "    )\n",
    "\n",
    "    #print(f\"‚úÖ Video anotado guardado en: {save_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fdf27-7c74-4b61-996b-baeef195ef21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
